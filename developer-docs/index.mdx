---
title: "Introduction"
description: "Get started with AI context in general, and Alchemyst in particular."
---


## Overview

Alchemyst is the context layer for LLMs and AI agents. It helps you store, retrieve, and manage context so AI systems stay accurate, relevant, and consistent over time. Whether youâ€™re plugging memory into an existing workflow or building a new agent from scratch, Alchemyst handles the messy parts of context - so you can focus on shipping.

Key outcomes you can expect from Alchemyst:

- **Aggregate and enrich data** from diverse sources, making it accessible to LLMs and agents in real time.
- **Maintain persistent, context-aware memory** to enhance reasoning, retrieval, and generation.
- **Orchestrate complex workflows** by connecting specialized frameworks, libraries, and platforms.
- **Deploy modular, scalable AI solutions** that are easy to maintain and extend.


## What is Alchemyst?

Alchemyst is a developer-first platform focused on AI context management and runtime orchestration. It offers:

- **Context management**: Store, index, and retrieve context in ways that improve model outputs.
- **SDKs & APIs**: Official SDKs for Python and TypeScript plus a rich REST API surface for other languages and environments.
- **Integration tooling**: Built-in connectors and examples for popular tools and editors to accelerate development.
- **Sample projects & best practices**: Real-world examples you can adapt to jumpstart your work


## Why Alchemyst?

- **Boost AI accuracy and relevance** by giving your models the context they need.
- **Accelerate development** with robust SDKs for Python and TypeScript.
- **Integrate seamlessly** with popular tools like VS Code, GitHub Copilot, and more.
- **Leverage real-world examples** and best practices from our community and team projects.


## How Alchemyst works

- **Ingest**: Bring data from databases, files, user interactions, and external APIs.
- **Enrich & Index**: Normalize and enrich data, then index it for fast retrieval by your agents or LLM prompts.
- **Serve context**: Provide contextual snippets and memories to models at inference time.
- **Orchestrate**: Chain tools and services to create deterministic workflows and agent behaviors.
- **Persist & Evolve**: Store user- or application-level memory that can be updated and audited over time.

